# Exercice 2 : Serveur MCP + RAG pour base d'avis

**Dur√©e** : 2 heures  
**Format** : Semi-ouvert avec checkpoints  
**Bin√¥mes** : Possibles mais non obligatoires

---

## üéØ Objectifs p√©dagogiques

√Ä la fin de cet exercice, vous saurez :

- ‚úÖ Comprendre et utiliser le Model Context Protocol (MCP)
- ‚úÖ G√©n√©rer des embeddings avec l'API OpenAI
- ‚úÖ Stocker et interroger une base vectorielle (ChromaDB)
- ‚úÖ Cr√©er un serveur MCP exposant des tools
- ‚úÖ Connecter Claude Code √† votre serveur MCP
- ‚úÖ Impl√©menter un syst√®me RAG (Retrieval Augmented Generation)

---

## üìñ Contexte m√©tier

Vous avez une base de donn√©es d'**avis clients** sur des agences immobili√®res Immodvisor.

**Probl√®me** :

- Claude Code ne conna√Æt pas ces avis (donn√©es priv√©es)
- Vous voulez interroger s√©mantiquement : "Quels sont les avis positifs sur l'accueil ?" ou "Trouve les probl√®mes r√©currents"

**Solution : RAG via MCP**

1. Indexer les avis dans une base vectorielle (embeddings OpenAI)
2. Cr√©er un serveur MCP qui expose des tools de recherche
3. Connecter Claude Code au serveur MCP
4. Claude peut maintenant interroger vos avis !

---

## üèóÔ∏è Architecture globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Claude Code   ‚îÇ
‚îÇ   (MCP Client)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ MCP Protocol (stdio/SSE)
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   MCP Server    ‚îÇ
‚îÇ   (Node.js ou   ‚îÇ
‚îÇ    Python)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îú‚îÄ‚îÄ Tool: search_reviews(query, limit)
         ‚îú‚îÄ‚îÄ Tool: get_stats(agencyId?)
         ‚îî‚îÄ‚îÄ Tool: analyze_sentiment(agencyId?)
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ChromaDB      ‚îÇ
‚îÇ   (Base         ‚îÇ
‚îÇ    vectorielle) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îî‚îÄ‚îÄ Embeddings (OpenAI Ada)
              ‚îî‚îÄ‚îÄ Avis Immodvisor
```

---

## üöÄ D√©roul√© de l'exercice

### Checkpoint 1 : G√©n√©ration du dataset (30 min)

#### 1.1 Cr√©er un jeu de donn√©es r√©aliste (15 min)

**T√¢che** : G√©n√©rer 50-100 faux avis Immodvisor avec l'IA.

**Prompt sugg√©r√© pour Claude Code** :

```markdown
G√©n√®re 100 avis d'agences immobili√®res r√©alistes en fran√ßais pour Immodvisor.

Crit√®res :

- Vari√©t√© de notes : 20% de 1-2 √©toiles, 30% de 3 √©toiles, 50% de 4-5 √©toiles
- Longueur variable : 50 √† 400 caract√®res
- Ton naturel et authentique (pas marketing)
- Mix de types : achat, vente, location
- Th√®mes vari√©s : accueil, professionnalisme, r√©activit√©, prix, qualit√© du conseil, etc.
- Inclure quelques avis n√©gatifs r√©alistes (lenteur, manque de suivi, frais cach√©s)

Format JSON :
{
"reviews": [
{
"id": "uuid v4",
"agencyId": "uuid v4",
"agencyName": "Nom de l'agence (var i√©e : Immo Paris 15, Century 21 Lyon, etc.)",
"rating": 1-5,
"comment": "Texte de l'avis",
"authorEmail": "email",
"authorName": "Pr√©nom Nom",
"prestationType": "achat|vente|location",
"createdAt": "2024-01-01T10:00:00Z"
}
]
}

Sauvegarde dans `data/reviews-dataset.json`
```

**Livrable** : `data/reviews-dataset.json` (50-100 avis)

---

#### 1.2 V√©rifier la qualit√© du dataset (5 min)

**T√¢che** : S'assurer que les avis sont diversifi√©s.

**Commandes** :

```bash
# Compter les avis par note
cat data/reviews-dataset.json | jq '.reviews | group_by(.rating) | map({rating: .[0].rating, count: length})'

# V√©rifier les th√®mes (mots-cl√©s)
cat data/reviews-dataset.json | jq -r '.reviews[].comment' | grep -i "professionnel\|accueil\|r√©actif\|lent\|cher"
```

---

#### 1.3 Installer les d√©pendances (10 min)

**T√¢che** : Pr√©parer l'environnement Python ou Node.js.

**Option A : Python** (recommand√© si d√©j√† install√©)

```bash
# Cr√©er un environnement virtuel
cd exercice-2-mcp-rag
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer les d√©pendances
pip install chromadb openai python-dotenv mcp

# Cr√©er .env
echo "OPENAI_API_KEY=sk-..." > .env
```

**Option B : Node.js** (si pr√©f√©rence TypeScript)

```bash
# Initialiser le projet
cd exercice-2-mcp-rag
npm init -y

# Installer les d√©pendances
npm install chromadb openai dotenv @modelcontextprotocol/sdk

# Cr√©er .env
echo "OPENAI_API_KEY=sk-..." > .env
```

**Livrable** : Environnement pr√™t avec d√©pendances install√©es

---

### Checkpoint 2 : Indexation des avis (45 min)

#### 2.1 G√©n√©rer les embeddings (20 min)

**T√¢che** : Transformer chaque avis en vecteur (embedding) avec l'API OpenAI.

**Script Python sugg√©r√©** : `scripts/index_reviews.py`

```python
import json
import os
from openai import OpenAI
from chromadb import Client
from chromadb.config import Settings
from dotenv import load_dotenv

load_dotenv()

# Configuration
client_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
client_chroma = Client(Settings(
    persist_directory="./chroma_db"
))

# Cr√©er ou r√©cup√©rer la collection
collection = client_chroma.get_or_create_collection(
    name="immodvisor_reviews",
    metadata={"description": "Avis clients Immodvisor"}
)

# Charger les avis
with open("../data/reviews-dataset.json") as f:
    data = json.load(f)
    reviews = data["reviews"]

print(f"üìä Indexation de {len(reviews)} avis...")

# G√©n√©rer les embeddings et indexer
for i, review in enumerate(reviews):
    # Cr√©er le texte √† embedder (combinaison de champs pertinents)
    text_to_embed = f"""
    Agence: {review['agencyName']}
    Note: {review['rating']}/5
    Type: {review['prestationType']}
    Avis: {review['comment']}
    Auteur: {review['authorName']}
    """

    # G√©n√©rer l'embedding avec OpenAI
    response = client_openai.embeddings.create(
        model="text-embedding-3-small",  # Mod√®le √©conomique
        input=text_to_embed
    )
    embedding = response.data[0].embedding

    # Ajouter √† ChromaDB
    collection.add(
        ids=[review["id"]],
        embeddings=[embedding],
        metadatas=[{
            "agencyId": review["agencyId"],
            "agencyName": review["agencyName"],
            "rating": review["rating"],
            "prestationType": review["prestationType"],
            "authorName": review["authorName"],
            "createdAt": review["createdAt"]
        }],
        documents=[review["comment"]]  # Texte de l'avis
    )

    if (i + 1) % 10 == 0:
        print(f"‚úÖ {i + 1}/{len(reviews)} avis index√©s")

print("üéâ Indexation termin√©e !")
print(f"üìÅ Base vectorielle sauvegard√©e dans ./chroma_db")
```

**Prompt pour Claude Code** (si g√©n√©ration assist√©e) :

```markdown
Cr√©e un script Python qui :

1. Charge les avis depuis `data/reviews-dataset.json`
2. Pour chaque avis, g√©n√®re un embedding avec OpenAI API (model: text-embedding-3-small)
3. Stocke dans ChromaDB avec m√©tadonn√©es (agencyId, rating, etc.)
4. Affiche la progression

D√©pendances : openai, chromadb, python-dotenv
Fichier : scripts/index_reviews.py
```

**Lancer le script** :

```bash
python scripts/index_reviews.py
```

**Livrable** : Base ChromaDB peupl√©e dans `./chroma_db/`

---

#### 2.2 Tester la recherche vectorielle (10 min)

**T√¢che** : V√©rifier que la recherche s√©mantique fonctionne.

**Script de test** : `scripts/test_search.py`

```python
from chromadb import Client
from chromadb.config import Settings
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

client_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
client_chroma = Client(Settings(persist_directory="./chroma_db"))

collection = client_chroma.get_collection("immodvisor_reviews")

# Test de recherche s√©mantique
query = "avis positifs sur l'accueil et le professionnalisme"

print(f"üîç Recherche : {query}\n")

# G√©n√©rer l'embedding de la requ√™te
response = client_openai.embeddings.create(
    model="text-embedding-3-small",
    input=query
)
query_embedding = response.data[0].embedding

# Rechercher les avis similaires
results = collection.query(
    query_embeddings=[query_embedding],
    n_results=5
)

# Afficher les r√©sultats
for i, (doc, metadata, distance) in enumerate(zip(
    results["documents"][0],
    results["metadatas"][0],
    results["distances"][0]
)):
    print(f"--- R√©sultat {i+1} (similarit√©: {1 - distance:.2f}) ---")
    print(f"Agence: {metadata['agencyName']}")
    print(f"Note: {metadata['rating']}/5")
    print(f"Avis: {doc}")
    print()
```

**Lancer le test** :

```bash
python scripts/test_search.py
```

**R√©sultat attendu** : 5 avis pertinents sur l'accueil et le professionnalisme

---

#### 2.3 Optimiser le chunking (15 min - optionnel)

**Si les avis sont tr√®s longs**, d√©couper en chunks pour am√©liorer la pr√©cision.

**Strat√©gie** : Comme les avis sont courts (< 400 caract√®res), **pas de chunking n√©cessaire**.

**Si vous voulez exp√©rimenter** :

```python
# Pour des avis plus longs, d√©couper par phrases
def chunk_text(text, max_length=200):
    sentences = text.split('. ')
    chunks = []
    current_chunk = ""

    for sentence in sentences:
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence + ". "
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "

    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks
```

---

### Checkpoint 3 : Cr√©ation du serveur MCP (45 min)

#### 3.1 Structure du serveur MCP (10 min)

**T√¢che** : Cr√©er la structure du serveur MCP.

**Architecture** :

```
mcp-server/
‚îú‚îÄ‚îÄ server.py (ou index.js)
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ search_reviews.py
‚îÇ   ‚îú‚îÄ‚îÄ get_stats.py
‚îÇ   ‚îî‚îÄ‚îÄ analyze_sentiment.py
‚îú‚îÄ‚îÄ chroma_db/ (lien symbolique ou copie)
‚îî‚îÄ‚îÄ .env
```

---

#### 3.2 Impl√©menter le serveur MCP Python (25 min)

**Fichier** : `mcp-server/server.py`

```python
import json
import os
from mcp.server import Server
from mcp.server.stdio import stdio_server
from chromadb import Client
from chromadb.config import Settings
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# Configuration
client_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
client_chroma = Client(Settings(persist_directory="../chroma_db"))
collection = client_chroma.get_collection("immodvisor_reviews")

# Cr√©er le serveur MCP
server = Server("immodvisor-reviews")

# Tool 1: Recherche s√©mantique
@server.tool()
async def search_reviews(query: str, limit: int = 5) -> str:
    """
    Recherche s√©mantique dans les avis d'agences immobili√®res.

    Args:
        query: Requ√™te en langage naturel (ex: "avis positifs sur l'accueil")
        limit: Nombre de r√©sultats √† retourner (d√©faut: 5)

    Returns:
        JSON avec les avis pertinents
    """
    # G√©n√©rer l'embedding de la requ√™te
    response = client_openai.embeddings.create(
        model="text-embedding-3-small",
        input=query
    )
    query_embedding = response.data[0].embedding

    # Rechercher les avis similaires
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=limit
    )

    # Formater les r√©sultats
    reviews = []
    for doc, metadata, distance in zip(
        results["documents"][0],
        results["metadatas"][0],
        results["distances"][0]
    ):
        reviews.append({
            "agencyName": metadata["agencyName"],
            "rating": metadata["rating"],
            "comment": doc,
            "similarity": round(1 - distance, 3)
        })

    return json.dumps({"query": query, "results": reviews}, ensure_ascii=False, indent=2)


# Tool 2: Statistiques
@server.tool()
async def get_stats(agencyId: str = None) -> str:
    """
    Retourne des statistiques sur les avis.

    Args:
        agencyId: (Optionnel) ID de l'agence pour filtrer

    Returns:
        JSON avec les statistiques
    """
    # R√©cup√©rer tous les avis (ou filtr√©s par agence)
    if agencyId:
        results = collection.get(where={"agencyId": agencyId})
    else:
        results = collection.get()

    # Calculer les statistiques
    ratings = [meta["rating"] for meta in results["metadatas"]]

    stats = {
        "total": len(ratings),
        "averageRating": round(sum(ratings) / len(ratings), 2) if ratings else 0,
        "distribution": {
            "1star": ratings.count(1),
            "2stars": ratings.count(2),
            "3stars": ratings.count(3),
            "4stars": ratings.count(4),
            "5stars": ratings.count(5),
        }
    }

    return json.dumps(stats, ensure_ascii=False, indent=2)


# Tool 3: Analyse de sentiment
@server.tool()
async def analyze_sentiment(agencyId: str = None) -> str:
    """
    Analyse le sentiment global des avis (positif/n√©gatif/neutre).

    Args:
        agencyId: (Optionnel) ID de l'agence pour filtrer

    Returns:
        JSON avec l'analyse de sentiment
    """
    # R√©cup√©rer les avis
    if agencyId:
        results = collection.get(where={"agencyId": agencyId})
    else:
        results = collection.get()

    # Analyser les sentiments bas√©s sur les notes
    ratings = [meta["rating"] for meta in results["metadatas"]]

    positive = sum(1 for r in ratings if r >= 4)
    neutral = sum(1 for r in ratings if r == 3)
    negative = sum(1 for r in ratings if r <= 2)

    total = len(ratings)

    sentiment = {
        "totalReviews": total,
        "sentiment": {
            "positive": {"count": positive, "percentage": round(positive / total * 100, 1)},
            "neutral": {"count": neutral, "percentage": round(neutral / total * 100, 1)},
            "negative": {"count": negative, "percentage": round(negative / total * 100, 1)},
        }
    }

    return json.dumps(sentiment, ensure_ascii=False, indent=2)


# Lancer le serveur
if __name__ == "__main__":
    import asyncio
    asyncio.run(stdio_server(server))
```

**Prompt pour Claude Code** (si g√©n√©ration assist√©e) :

```markdown
Cr√©e un serveur MCP Python qui expose 3 tools :

1. search_reviews(query: str, limit: int = 5)

   - Recherche s√©mantique dans ChromaDB
   - G√©n√®re embedding de la query avec OpenAI
   - Retourne les top-k avis similaires

2. get_stats(agencyId: str = None)

   - Statistiques : total, moyenne, distribution des notes
   - Filtrage optionnel par agence

3. analyze_sentiment(agencyId: str = None)
   - Analyse positive/neutre/n√©gatif bas√© sur les notes
   - Retourne count et pourcentages

Utilise : mcp.server, chromadb, openai
Fichier : mcp-server/server.py
```

---

#### 3.3 Configurer Claude Code pour utiliser le serveur MCP (10 min)

**T√¢che** : Connecter Claude Code √† votre serveur MCP.

**Fichier de config** : `.cursor/mcp.json` ou `~/.config/claude/mcp.json` (selon votre installation)

```json
{
  "mcpServers": {
    "immodvisor-reviews": {
      "command": "python",
      "args": ["/chemin/absolu/vers/mcp-server/server.py"],
      "env": {
        "OPENAI_API_KEY": "sk-..."
      }
    }
  }
}
```

**Red√©marrer Claude Code** pour charger la config.

**V√©rifier** :

- Ouvrir Claude Code
- Taper : "Liste les tools MCP disponibles"
- Vous devriez voir : `search_reviews`, `get_stats`, `analyze_sentiment`

---

### Checkpoint 4 : Tests et d√©mo (30 min)

#### 4.1 Tester le serveur MCP depuis Claude Code (15 min)

**T√¢che** : Interroger vos avis via Claude Code.

**Exemples de requ√™tes** :

1. **Recherche s√©mantique** :

   ```
   Utilise le tool search_reviews pour trouver les avis positifs sur l'accueil.
   ```

2. **Statistiques globales** :

   ```
   Donne-moi les statistiques de tous les avis avec get_stats.
   ```

3. **Analyse de sentiment** :

   ```
   Analyse le sentiment global des avis avec analyze_sentiment.
   ```

4. **Question complexe** (RAG en action) :

   ```
   Quels sont les probl√®mes r√©currents mentionn√©s dans les avis n√©gatifs (note ‚â§ 2) ?

   (Claude va appeler search_reviews avec query="probl√®mes r√©currents avis n√©gatifs")
   ```

**R√©sultat attendu** : Claude r√©pond en langage naturel en utilisant les donn√©es de votre MCP.

---

#### 4.2 Cas d'usage avanc√©s (10 min)

**Tester des sc√©narios r√©alistes** :

**Sc√©nario 1 : Analyse comparative**

```
Compare les avis sur les agences de Paris vs Lyon. Quelle ville a les meilleures notes en moyenne ?
```

**Sc√©nario 2 : Insights m√©tier**

```
Quels sont les 3 th√®mes les plus mentionn√©s dans les avis 5 √©toiles ?
Et dans les avis 1-2 √©toiles ?
```

**Sc√©nario 3 : Recommandation**

```
Un client cherche une agence professionnelle et r√©active √† Paris.
Recommande-lui les 3 meilleures agences bas√©es sur les avis.
```

---

#### 4.3 D√©mo collective (5 min)

**Format** : Montrer votre serveur MCP en action.

**Pr√©senter** :

1. Votre dataset d'avis
2. La base vectorielle ChromaDB
3. Une requ√™te complexe √† Claude Code
4. La r√©ponse g√©n√©r√©e avec donn√©es r√©elles

---

## üìä Grille d'√©valuation (auto-√©valuation)

| Crit√®re                                       | Oui ‚úÖ | Non ‚ùå | Remarque |
| --------------------------------------------- | ------ | ------ | -------- |
| **Dataset** : 50-100 avis g√©n√©r√©s             |        |        |          |
| **Indexation** : Embeddings cr√©√©s avec OpenAI |        |        |          |
| **ChromaDB** : Base vectorielle fonctionnelle |        |        |          |
| **MCP Server** : 3 tools impl√©ment√©s          |        |        |          |
| **Config** : Claude Code connect√© au serveur  |        |        |          |
| **Test** : Recherche s√©mantique fonctionne    |        |        |          |
| **RAG** : Questions complexes r√©pondues       |        |        |          |

---

## üéÅ Bonus (si temps disponible)

### Bonus 1 : Filtres avanc√©s

Ajouter des param√®tres de filtrage :

```python
@server.tool()
async def search_reviews(
    query: str,
    limit: int = 5,
    min_rating: int = None,
    max_rating: int = None,
    prestation_type: str = None
) -> str:
    # Impl√©menter les filtres avec ChromaDB where clause
    ...
```

---

### Bonus 2 : Cache des embeddings

√âviter de r√©g√©n√©rer l'embedding de la m√™me query :

```python
import hashlib
import pickle

embedding_cache = {}

def get_cached_embedding(text: str):
    cache_key = hashlib.md5(text.encode()).hexdigest()

    if cache_key in embedding_cache:
        return embedding_cache[cache_key]

    response = client_openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    embedding = response.data[0].embedding
    embedding_cache[cache_key] = embedding

    return embedding
```

---

### Bonus 3 : M√©triques de co√ªt

Tracker les appels API OpenAI :

```python
import time

metrics = {
    "total_queries": 0,
    "total_tokens": 0,
    "total_cost_usd": 0
}

@server.tool()
async def get_metrics() -> str:
    """Retourne les m√©triques d'utilisation du serveur MCP"""
    return json.dumps(metrics, indent=2)
```

---

### Bonus 4 : Multi-collection

Cr√©er plusieurs collections (avis, documentation interne, tickets JIRA) :

```python
collections = {
    "reviews": client_chroma.get_collection("immodvisor_reviews"),
    "docs": client_chroma.get_collection("internal_docs"),
}

@server.tool()
async def search_all(query: str) -> str:
    """Recherche dans toutes les collections"""
    results = {}
    for name, collection in collections.items():
        results[name] = collection.query(...)
    return json.dumps(results)
```

---

## üí° Points cl√©s √† retenir

### MCP (Model Context Protocol)

- Protocole standardis√© pour connecter outils externes aux LLMs
- Architecture : Client (Claude) ‚Üî Server (Python/Node) ‚Üî Data
- Tools = fonctions expos√©es au LLM (comme des APIs)

### RAG (Retrieval Augmented Generation)

- Permet d'acc√©der √† des donn√©es priv√©es/r√©centes
- Pipeline : Query ‚Üí Embedding ‚Üí Recherche vectorielle ‚Üí G√©n√©ration
- √âconomise des tokens (seulement top-k r√©sultats dans le contexte)

### Embeddings

- Repr√©sentation vectorielle du texte
- Textes similaires = vecteurs proches (similarit√© cosinus)
- OpenAI text-embedding-3-small : $0.02 par 1M tokens

### ChromaDB

- Base de donn√©es vectorielle simple et efficace
- Stockage local (pas besoin de serveur)
- Recherche par similarit√© cosinus

---

## üéì Cas d'usage r√©els chez Immodvisor

### Court terme

- ‚úÖ **RAG sur docs internes** : Indexer la documentation Symfony, API Platform, guidelines
- ‚úÖ **Recherche dans les tickets JIRA** : "Trouve les bugs r√©currents sur le module de paiement"
- ‚úÖ **Analyse d'avis** : D√©tecter les tendances, probl√®mes r√©currents

### Moyen terme

- ‚úÖ **Agent de support client** : R√©pondre aux questions bas√©es sur FAQ + historique
- ‚úÖ **Code review assistant** : Indexer les bonnes pratiques de la codebase
- ‚úÖ **Onboarding automatis√©** : Nouveau dev ‚Üí Questions sur le projet ‚Üí R√©ponses depuis docs index√©es

---

## üìö Ressources

### Documentation

- [Model Context Protocol](https://modelcontextprotocol.io/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)

### Tutoriels

- [Building a RAG System with ChromaDB](https://docs.trychroma.com/guides)
- [OpenAI Cookbook: Question Answering](https://cookbook.openai.com/)

### Alternatives √† ChromaDB

- **Pinecone** : Vector database cloud (payant)
- **Weaviate** : Open-source, self-hosted
- **Qdrant** : Rust-based, performant
- **PostgreSQL + pgvector** : Extension SQL pour vecteurs

---

**Session suivante** : [Finalisation de la charte d'utilisation](../charte/guidelines-vibe-coding.md)
